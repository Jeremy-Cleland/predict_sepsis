{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded dataset with 1,552,210 rows and 44 columns\n",
      "\n",
      "Basic Dataset Information:\n",
      "--------------------------------------------------\n",
      "\n",
      "Dataset Shape: (1552210, 44)\n",
      "\n",
      "Columns: ['Unnamed: 0', 'Hour', 'HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp', 'EtCO2', 'BaseExcess', 'HCO3', 'FiO2', 'pH', 'PaCO2', 'SaO2', 'AST', 'BUN', 'Alkalinephos', 'Calcium', 'Chloride', 'Creatinine', 'Bilirubin_direct', 'Glucose', 'Lactate', 'Magnesium', 'Phosphate', 'Potassium', 'Bilirubin_total', 'TroponinI', 'Hct', 'Hgb', 'PTT', 'WBC', 'Fibrinogen', 'Platelets', 'Age', 'Gender', 'Unit1', 'Unit2', 'HospAdmTime', 'ICULOS', 'SepsisLabel', 'Patient_ID']\n",
      "\n",
      "Memory Usage: 521.07 MB\n",
      "\n",
      "Unit1 Analysis:\n",
      "--------------------------------------------------\n",
      "\n",
      "Top 10 most common Unit1 values:\n",
      "Unit1\n",
      "0.0    473349\n",
      "1.0    466901\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total unique Unit1 values: 2\n",
      "\n",
      "Unit2 Analysis:\n",
      "--------------------------------------------------\n",
      "\n",
      "Top 10 most common Unit2 values:\n",
      "Unit2\n",
      "1.0    473349\n",
      "0.0    466901\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total unique Unit2 values: 2\n",
      "\n",
      "Patient Analysis:\n",
      "--------------------------------------------------\n",
      "Total number of unique patients: 40,336\n",
      "\n",
      "Readings per patient:\n",
      "Mean: 38.48\n",
      "Median: 38.00\n",
      "Min: 8\n",
      "Max: 336\n",
      "\n",
      "Unit assignments per patient:\n",
      "\n",
      "Unit1:\n",
      "Unit1\n",
      "1    24719\n",
      "0    15617\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unit2:\n",
      "Unit2\n",
      "1    24719\n",
      "0    15617\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Patients with multiple Unit1 assignments: 0\n",
      "Patients with multiple Unit2 assignments: 0\n",
      "\n",
      "Most common Unit1-Unit2 combinations:\n",
      "   Unit1  Unit2   count\n",
      "0    0.0    1.0  473349\n",
      "1    1.0    0.0  466901\n",
      "\n",
      "Missing Values Analysis:\n",
      "--------------------------------------------------\n",
      "\n",
      "Columns with missing values:\n",
      "                  Missing Values  Percentage\n",
      "Bilirubin_direct         1549220   99.807371\n",
      "Fibrinogen               1541968   99.340167\n",
      "TroponinI                1537429   99.047745\n",
      "Bilirubin_total          1529069   98.509158\n",
      "Alkalinephos             1527269   98.393194\n",
      "AST                      1527027   98.377604\n",
      "Lactate                  1510764   97.329872\n",
      "PTT                      1506511   97.055875\n",
      "SaO2                     1498649   96.549372\n",
      "EtCO2                    1494574   96.286843\n",
      "Phosphate                1489909   95.986303\n",
      "HCO3                     1487182   95.810618\n",
      "Chloride                 1481744   95.460279\n",
      "BaseExcess               1468065   94.579020\n",
      "PaCO2                    1465909   94.440121\n",
      "Calcium                  1460879   94.116067\n",
      "Platelets                1460001   94.059502\n",
      "Creatinine               1457594   93.904433\n",
      "Magnesium                1454259   93.689578\n",
      "WBC                      1452763   93.593199\n",
      "BUN                      1445642   93.134434\n",
      "pH                       1444637   93.069688\n",
      "Hgb                      1437619   92.617558\n",
      "FiO2                     1422845   91.665754\n",
      "Hct                      1414777   91.145979\n",
      "Potassium                1407685   90.689082\n",
      "Glucose                  1286694   82.894325\n",
      "Temp                     1026984   66.162697\n",
      "Unit1                     611960   39.425078\n",
      "Unit2                     611960   39.425078\n",
      "DBP                       486554   31.345887\n",
      "Resp                      238335   15.354559\n",
      "SBP                       226265   14.576958\n",
      "O2Sat                     202736   13.061119\n",
      "MAP                       193270   12.451279\n",
      "HR                        153399    9.882619\n",
      "HospAdmTime                    8    0.000515\n",
      "\n",
      "Data Quality Checks:\n",
      "--------------------------------------------------\n",
      "\n",
      "Temp outliers:\n",
      "Values outside [25, 45]: 6\n",
      "Example values: [23.6, 21.0, 23.0, 20.9, 50.0]\n",
      "\n",
      "DBP outliers:\n",
      "Values outside [0, 200]: 103\n",
      "Example values: [246.0, 205.0, 211.0, 272.0, 268.0]\n",
      "\n",
      "Analysis complete. Summary saved to 'data_analysis_summary.txt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w_/t72srld50c1g82l0pg0719zw0000gn/T/ipykernel_15331/180353443.py:120: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  unit_time = df.groupby(\"Hour_bin\")[\"Unit1\"].value_counts().unstack()\n"
     ]
    }
   ],
   "source": [
    "# Data Analysis for Sepsis Prediction Dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "# Configuration\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "\n",
    "\n",
    "# Load the data\n",
    "def load_data(path=\"../data/raw/Dataset.csv\"):\n",
    "    print(\"Loading data...\")\n",
    "    df = pd.read_csv(path)\n",
    "    print(f\"Loaded dataset with {df.shape[0]:,} rows and {df.shape[1]} columns\")\n",
    "    return df\n",
    "\n",
    "\n",
    "df = load_data()\n",
    "\n",
    "# Basic Dataset Information\n",
    "print(\"\\nBasic Dataset Information:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"\\nDataset Shape:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "\n",
    "\n",
    "# Memory Usage\n",
    "def memory_usage(df):\n",
    "    memory = df.memory_usage(deep=True).sum()\n",
    "    for unit in [\"B\", \"KB\", \"MB\", \"GB\"]:\n",
    "        if memory < 1024:\n",
    "            return f\"{memory:.2f} {unit}\"\n",
    "        memory /= 1024\n",
    "\n",
    "\n",
    "print(f\"\\nMemory Usage: {memory_usage(df)}\")\n",
    "\n",
    "# Analyze Unit1 and Unit2\n",
    "print(\"\\nUnit1 Analysis:\")\n",
    "print(\"-\" * 50)\n",
    "unit1_counts = df[\"Unit1\"].value_counts()\n",
    "print(\"\\nTop 10 most common Unit1 values:\")\n",
    "print(unit1_counts.head(10))\n",
    "print(f\"\\nTotal unique Unit1 values: {len(unit1_counts)}\")\n",
    "\n",
    "print(\"\\nUnit2 Analysis:\")\n",
    "print(\"-\" * 50)\n",
    "unit2_counts = df[\"Unit2\"].value_counts()\n",
    "print(\"\\nTop 10 most common Unit2 values:\")\n",
    "print(unit2_counts.head(10))\n",
    "print(f\"\\nTotal unique Unit2 values: {len(unit2_counts)}\")\n",
    "\n",
    "# Analyze values per patient\n",
    "print(\"\\nPatient Analysis:\")\n",
    "print(\"-\" * 50)\n",
    "patients = df[\"Patient_ID\"].unique()\n",
    "print(f\"Total number of unique patients: {len(patients):,}\")\n",
    "\n",
    "# Calculate average readings per patient\n",
    "readings_per_patient = df.groupby(\"Patient_ID\").size()\n",
    "print(f\"\\nReadings per patient:\")\n",
    "print(f\"Mean: {readings_per_patient.mean():.2f}\")\n",
    "print(f\"Median: {readings_per_patient.median():.2f}\")\n",
    "print(f\"Min: {readings_per_patient.min()}\")\n",
    "print(f\"Max: {readings_per_patient.max()}\")\n",
    "\n",
    "\n",
    "# Analyze Unit assignments per patient\n",
    "def analyze_unit_assignments():\n",
    "    patient_units = df.groupby(\"Patient_ID\").agg(\n",
    "        {\"Unit1\": \"nunique\", \"Unit2\": \"nunique\"}\n",
    "    )\n",
    "\n",
    "    print(\"\\nUnit assignments per patient:\")\n",
    "    print(\"\\nUnit1:\")\n",
    "    print(patient_units[\"Unit1\"].value_counts().head())\n",
    "    print(\"\\nUnit2:\")\n",
    "    print(patient_units[\"Unit2\"].value_counts().head())\n",
    "\n",
    "    # Patients with multiple units\n",
    "    multi_unit1 = patient_units[patient_units[\"Unit1\"] > 1]\n",
    "    multi_unit2 = patient_units[patient_units[\"Unit2\"] > 1]\n",
    "\n",
    "    print(f\"\\nPatients with multiple Unit1 assignments: {len(multi_unit1)}\")\n",
    "    print(f\"Patients with multiple Unit2 assignments: {len(multi_unit2)}\")\n",
    "\n",
    "    return multi_unit1, multi_unit2\n",
    "\n",
    "\n",
    "multi_unit1, multi_unit2 = analyze_unit_assignments()\n",
    "\n",
    "\n",
    "# Examine a few patients with multiple unit assignments\n",
    "def examine_patient_units(patient_id):\n",
    "    patient_data = df[df[\"Patient_ID\"] == patient_id]\n",
    "    return patient_data[[\"Patient_ID\", \"Hour\", \"Unit1\", \"Unit2\"]].sort_values(\"Hour\")\n",
    "\n",
    "\n",
    "if len(multi_unit1) > 0:\n",
    "    print(\"\\nExample of patient with multiple Unit1 assignments:\")\n",
    "    sample_patient = multi_unit1.index[0]\n",
    "    print(examine_patient_units(sample_patient))\n",
    "\n",
    "\n",
    "# Check for patterns in Unit assignments\n",
    "def check_unit_patterns():\n",
    "    # Check if Unit2 is dependent on Unit1\n",
    "    unit_combinations = df.groupby([\"Unit1\", \"Unit2\"]).size().reset_index(name=\"count\")\n",
    "    unit_combinations = unit_combinations.sort_values(\"count\", ascending=False)\n",
    "\n",
    "    print(\"\\nMost common Unit1-Unit2 combinations:\")\n",
    "    print(unit_combinations.head(10))\n",
    "\n",
    "    # Check for temporal patterns\n",
    "    df[\"Hour_bin\"] = pd.cut(df[\"Hour\"], bins=24, labels=range(24))\n",
    "    unit_time = df.groupby(\"Hour_bin\")[\"Unit1\"].value_counts().unstack()\n",
    "\n",
    "    return unit_combinations, unit_time\n",
    "\n",
    "\n",
    "unit_combinations, unit_time = check_unit_patterns()\n",
    "\n",
    "\n",
    "# Missing Values Analysis\n",
    "def analyze_missing_values(df):\n",
    "    missing = df.isnull().sum()\n",
    "    missing_pct = (missing / len(df)) * 100\n",
    "    missing_stats = pd.DataFrame(\n",
    "        {\"Missing Values\": missing, \"Percentage\": missing_pct}\n",
    "    ).sort_values(\"Percentage\", ascending=False)\n",
    "\n",
    "    print(\"\\nMissing Values Analysis:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\"\\nColumns with missing values:\")\n",
    "    print(missing_stats[missing_stats[\"Missing Values\"] > 0])\n",
    "\n",
    "    return missing_stats\n",
    "\n",
    "\n",
    "missing_stats = analyze_missing_values(df)\n",
    "\n",
    "\n",
    "# Data Quality Checks\n",
    "def data_quality_checks(df):\n",
    "    print(\"\\nData Quality Checks:\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Check for obvious errors in vital signs\n",
    "    vitals = {\n",
    "        \"HR\": (0, 300),  # Heart rate in bpm\n",
    "        \"O2Sat\": (0, 100),  # Oxygen saturation percentage\n",
    "        \"Temp\": (25, 45),  # Temperature in Celsius\n",
    "        \"SBP\": (0, 300),  # Systolic blood pressure\n",
    "        \"DBP\": (0, 200),  # Diastolic blood pressure\n",
    "        \"Resp\": (0, 100),  # Respiratory rate\n",
    "    }\n",
    "\n",
    "    for vital, (min_val, max_val) in vitals.items():\n",
    "        if vital in df.columns:\n",
    "            outliers = df[(df[vital] < min_val) | (df[vital] > max_val)][vital]\n",
    "            if len(outliers) > 0:\n",
    "                print(f\"\\n{vital} outliers:\")\n",
    "                print(f\"Values outside [{min_val}, {max_val}]: {len(outliers)}\")\n",
    "                print(f\"Example values: {outliers.head().tolist()}\")\n",
    "\n",
    "\n",
    "data_quality_checks(df)\n",
    "\n",
    "\n",
    "# Save summary to file\n",
    "def save_analysis_summary(filename=\"data_analysis_summary.txt\"):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"Data Analysis Summary\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "\n",
    "        # Dataset basics\n",
    "        f.write(f\"Dataset Shape: {df.shape}\\n\")\n",
    "        f.write(f\"Memory Usage: {memory_usage(df)}\\n\")\n",
    "        f.write(f\"Number of Patients: {len(patients):,}\\n\\n\")\n",
    "\n",
    "        # Unit analysis\n",
    "        f.write(\"Unit Analysis\\n\")\n",
    "        f.write(\"-\" * 20 + \"\\n\")\n",
    "        f.write(f\"Unique Unit1 values: {len(unit1_counts)}\\n\")\n",
    "        f.write(f\"Unique Unit2 values: {len(unit2_counts)}\\n\")\n",
    "        f.write(f\"Patients with multiple Unit1: {len(multi_unit1)}\\n\")\n",
    "        f.write(f\"Patients with multiple Unit2: {len(multi_unit2)}\\n\\n\")\n",
    "\n",
    "        # Missing values\n",
    "        f.write(\"Missing Values Summary\\n\")\n",
    "        f.write(\"-\" * 20 + \"\\n\")\n",
    "        f.write(missing_stats[missing_stats[\"Missing Values\"] > 0].to_string())\n",
    "\n",
    "\n",
    "save_analysis_summary()\n",
    "\n",
    "print(\"\\nAnalysis complete. Summary saved to 'data_analysis_summary.txt'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predictsepsis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
